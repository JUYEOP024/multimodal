{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ-ct8RYCiVk"
   },
   "source": [
    "# Pretrained CNN Models\n",
    "\n",
    "https://www.image-net.org/challenges/LSVRC/\n",
    "\n",
    "**LSVRC(이미지넷 대규모 시각 인식 챌린지 Large Scale Visual Recognition Challenge)**는  \n",
    "**ImageNet** 데이터셋을 이용해 이미지 분류와 객체 탐지 등 컴퓨터 비전 알고리즘의 성능을 겨루는 국제 대회이다.  \n",
    "2010년부터 개최되었고, 2012년 **AlexNet**의 우승을 계기로 딥러닝이 본격적으로 주목받기 시작했다.  \n",
    "이후 **VGGNet**, **GoogLeNet**, **ResNet** 등 혁신적인 딥러닝 모델들이 이 대회를 통해 등장하며 컴퓨터 비전 발전을 이끌었다.\n",
    "\n",
    "![](https://d.pr/i/9p1so1+)\n",
    "\n",
    "\n",
    "| **세대**   | **주요 모델**                              | **특징**                                                                                           |\n",
    "|------------|--------------------------------------------|----------------------------------------------------------------------------------------------------|\n",
    "| **1세대**  | LeNet, AlexNet, VGG                       | - Conv → ReLU → Pooling으로 이어지는 CNN 기본 구조 확립                                          |\n",
    "| **2세대**  | GoogLeNet(Inception), Inception v2/v3/v4, <br>InceptionResNet, Xception | - 다양한 크기의 필터를 한꺼번에 결합<br>- 1x1 Convolution으로 계산량 감소 및 네트워크 효율성 증대 |\n",
    "| **3세대**  | MobileNet(v1, v2), SeNet, NasNet, EfficientNet | - 네트워크 Depth/파라미터 감소 및 최적화<br>- Depthwise Convolution으로 계산 효율성 향상<br>- 필터 Channel 수, Kernel 크기 등의 하이퍼파라미터를 Auto Search로 최적화 |\n",
    "\n",
    "\n",
    "\n",
    "![https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5](https://d.pr/i/HwLSVx+)\n",
    "\n",
    "\n",
    "**프레임워크별 사용가능한 pre-trained models**\n",
    "\n",
    "- keras/tensorflow: https://keras.io/api/applications/\n",
    "- pytorch: https://docs.pytorch.org/vision/main/models.html\n",
    "\n",
    "\n",
    "**성능지표 Top-n Accuracy, Top-n Error**\n",
    "\n",
    "1. **Top-1 정확도**:\n",
    "    - 모델이 예측한 가장 높은 확률의 클래스가 실제 정답인 경우의 비율\n",
    "    - 예를 들어, Top-1 정확도가 77.1%라면, 모델이 최상위로 예측한 클래스가 77.1% 확률로 정답이라는 의미\n",
    "2. **Top-5 정확도**:\n",
    "    - 모델이 예측한 상위 5개의 클래스 중 하나라도 정답인 경우의 비율\n",
    "    - 예를 들어, Top-5 정확도가 93.3%라면, 모델이 예측한 상위 5개의 클래스 중 하나가 정답일 확률이 93.3%라는 의미\n",
    "3. **Top-5 오류율**:\n",
    "    - 상위 5개의 예측 결과 중 어느 하나도 정답을 포함하지 않을 확률. **Top-5 오류율 = 1 - Top-5 정확도**로 계산한다.\n",
    "    - 예를 들어, Top-5 정확도가 93.3%라면, Top-5 오류율은 6.7%이다. 이는 모델이 상위 5개 예측 결과 중 어느 하나도 정답을 포함하지 않을 확률이 6.7%라는 의미\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1769580267504,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "ggswzC52COBx"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# 1. 환경 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 10 # CIFAR10\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18532,
     "status": "ok",
     "timestamp": 1769578672991,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "gRw97nxMFzaw",
    "outputId": "022604ef-a2c6-441a-fb15-10ee31021e2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jy/SKN23/multimodal/multi_venv/lib/python3.12/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "# 2. 데이터 전처리 및 DataLoader\n",
    "# - 수백만 장의 ImageNet 이미지를 분석해서 구한 RGB 채널별 통계값입니다.\n",
    "# - Mean (평균): Red 0.485, Green 0.456, Blue 0.406\n",
    "# - Std (표준편차): Red 0.229, Green 0.224, Blue 0.225\n",
    "# - torchvision.models에서 제공하는 사전 학습된 모델들(ResNet, VGG, DenseNet 등)은 모두 이 값으로 정규화된 상태에서 학습되었으므로,\n",
    "# - 사용할 이미지를 이 모델에 넣을 때도 똑같은 기준으로 정규화를 해줘야 모델이 학습했던 데이터 분포와 비슷해져서 성능이 제대로 나온다.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "val_dataset   = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = torch.utils.data.DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1769580277813,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "ROyvfeLCGHdi",
    "outputId": "479f0d91-d4df-4511-cd3f-e39b46ef3514"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jy/SKN23/multimodal/multi_venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "학습할 파라미터: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0182, -0.0179, -0.0409,  ..., -0.0142, -0.0084,  0.0287],\n",
       "         [-0.0125, -0.0411, -0.0369,  ..., -0.0194, -0.0274,  0.0155],\n",
       "         [-0.0230,  0.0300,  0.0428,  ...,  0.0063, -0.0386, -0.0069],\n",
       "         ...,\n",
       "         [-0.0038, -0.0392, -0.0025,  ...,  0.0382, -0.0238,  0.0254],\n",
       "         [ 0.0013, -0.0054,  0.0158,  ...,  0.0267,  0.0205, -0.0061],\n",
       "         [ 0.0277, -0.0425, -0.0413,  ..., -0.0440, -0.0157,  0.0253]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0115, -0.0268, -0.0408,  0.0381, -0.0372,  0.0433,  0.0039,  0.0116,\n",
       "         -0.0321, -0.0341], requires_grad=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 사전학습된 모델 불러오기 및 분류기 교체\n",
    "model = models.resnet18(weights=True)\n",
    "print(model)\n",
    "\n",
    "# 모든 파라미터 동결\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# FC 레이어 교체\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes) # required_grad=True 학습대상\n",
    "model = model.to(device)\n",
    "\n",
    "# 학습 대상 파라미터 확인\n",
    "params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
    "print('학습할 파라미터: ')\n",
    "params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2884782,
     "status": "ok",
     "timestamp": 1769583162873,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "iUOfn5-CG6_X",
    "outputId": "f122e9c5-e75e-4d2f-8bf4-74ba94333c64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 229/782 [09:15<19:45,  2.14s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# 4. 손실함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params_to_update, lr=learning_rate)\n",
    "\n",
    "# 스케줄러: 검증 손실이 정체될 때 학습률을 0.1배로 감소시킴\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "# Early Stopping 객체 생성\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, path='best_model.pt')\n",
    "\n",
    "# 5. 학습 및 검증 함수 정의\n",
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# 6. 메인 학습 루프\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc     = validate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Learning Rate Scheduler 단계 업데이트\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early Stopping 단계 업데이트\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "\n",
    "# 7. 최적의 모델 불러오기 및 최종 테스트\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, criterion)\n",
    "print(f\"Final Test Acc (Best Model): {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAviueU-NDC-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0BbaSHS2todGZzsZCuh9m",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "multi_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
