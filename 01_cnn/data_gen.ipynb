{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e6a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jy/SKN23/multimodal/multi_venv/lib/python3.12/site-packages/keras/src/datasets/cifar.py:18: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  d = cPickle.load(f, encoding=\"bytes\")\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e593f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jy/SKN23/multimodal/multi_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4694 - loss: 1.4820 - val_accuracy: 0.5576 - val_loss: 1.2680\n",
      "Epoch 2/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.5828 - loss: 1.1925 - val_accuracy: 0.5896 - val_loss: 1.1863\n",
      "Epoch 3/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6199 - loss: 1.0842 - val_accuracy: 0.6070 - val_loss: 1.0997\n",
      "Epoch 4/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.6518 - loss: 0.9948 - val_accuracy: 0.6250 - val_loss: 1.0877\n",
      "Epoch 5/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.6752 - loss: 0.9287 - val_accuracy: 0.6220 - val_loss: 1.1004\n",
      "Epoch 6/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.6943 - loss: 0.8707 - val_accuracy: 0.6484 - val_loss: 1.0394\n",
      "Epoch 7/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.7149 - loss: 0.8196 - val_accuracy: 0.6554 - val_loss: 1.0158\n",
      "Epoch 8/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.7324 - loss: 0.7665 - val_accuracy: 0.6540 - val_loss: 1.0374\n",
      "Epoch 9/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.7485 - loss: 0.7239 - val_accuracy: 0.6546 - val_loss: 1.0429\n",
      "Epoch 10/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7620 - loss: 0.6801 - val_accuracy: 0.6598 - val_loss: 1.0773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x128ae1e20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 증강 없이 모델 학습 \n",
    "from tensorflow.keras.models import Sequential # 순차적 계층 구조를 정의하기 위한 모델 클래스 임포트\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense # 합성곱, 풀링, 평탄화, 전결합 레이어 임포트\n",
    "\n",
    "model = Sequential([ # 순차 모델 생성 시작\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape = (32, 32, 3)), # 32개 필터, 3x3 커널, ReLU 활성화 함수, 입력 이미지 크기 지정\n",
    "    MaxPooling2D((2, 2)), # 2x2 크기로 데이터 다운샘플링 (최대 풀링)\n",
    "    Flatten(), # 2차원 특징 맵을 1차원 벡터로 변환\n",
    "    Dense(64, activation = 'relu'), # 64개 노드의 은닉층, ReLU 활성화 함수 사용\n",
    "    Dense(10, activation = 'softmax') # 10개 클래스 분류를 위한 출력층, Softmax 활성화 함수 사용\n",
    "])\n",
    "\n",
    "model.compile( # 학습 프로세스 설정\n",
    "    optimizer = 'adam', # 최적화 알고리즘으로 Adam 사용\n",
    "    loss = 'sparse_categorical_crossentropy', # 정수형 타겟 값을 위한 다중 분류 손실 함수\n",
    "    metrics = ['accuracy'] # 평가 지표로 정확도 측정\n",
    ")\n",
    "\n",
    "# 데이터 정규화(0~1 사이) 및 10 에포크 학습 수행, 학습 데이터의 10%를 검증용으로 사용\n",
    "model.fit(x_train/ 255.0, y_train, epochs = 10, validation_split = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166b1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.5894 - loss: 1.1837 - val_accuracy: 0.6357 - val_loss: 1.0712\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.6021 - loss: 1.1382 - val_accuracy: 0.6531 - val_loss: 1.0089\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.6109 - loss: 1.1103 - val_accuracy: 0.6207 - val_loss: 1.1016\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6160 - loss: 1.0983 - val_accuracy: 0.6463 - val_loss: 1.0091\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.6234 - loss: 1.0762 - val_accuracy: 0.6517 - val_loss: 1.0184\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.6226 - loss: 1.0744 - val_accuracy: 0.6342 - val_loss: 1.0607\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6291 - loss: 1.0605 - val_accuracy: 0.6396 - val_loss: 1.0788\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6313 - loss: 1.0509 - val_accuracy: 0.6602 - val_loss: 1.0064\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6301 - loss: 1.0470 - val_accuracy: 0.6525 - val_loss: 1.0093\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.6377 - loss: 1.0387 - val_accuracy: 0.6575 - val_loss: 1.0147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x128d7c560>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 훈련 데이터용 이미지 생성기 (데이터 증강 포함)\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,           # 픽셀 값을 0~1 범위로 정규화\n",
    "    rotation_range=15,        # 무작위 회전 범위 (0~15도)\n",
    "    width_shift_range=0.1,    # 가로 방향 이동 비율 (10%)\n",
    "    height_shift_range=0.1,   # 세로 방향 이동 비율 (10%)\n",
    "    zoom_range=0.1,           # 무작위 확대/축소 범위 (10%)\n",
    "    horizontal_flip=True      # 무작위 좌우 반전 허용\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size = 64),\n",
    "    epochs = 10,\n",
    "    validation_data = (x_test/ 255.0,y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aadd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
